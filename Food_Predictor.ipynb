{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2rptU6mxyaoP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\azdanevy\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16W1-BvjtVmz"
      },
      "source": [
        "Let's pretend we have 3 users:\n",
        "1. User 1 is a vegetarian who is lactose intolerant. ü•ùüçÖ\n",
        "2. Unser 2 is an athlete who prefers meat dishes to vegetable dishes. üçñü•©\n",
        "3. Unser 3 - has no special preferences, eats mostly everything. üç≤üç†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "FDNshkxJvR-U"
      },
      "outputs": [],
      "source": [
        "user1 = {'id':'1293707', 'prefers': ['30-minutes-or-less',\n",
        "  'time-to-make',\n",
        "  'course',\n",
        "  'preparation',\n",
        "  'occasion',\n",
        "  'for-large-groups',\n",
        "  'low-protein',\n",
        "  'healthy',\n",
        "  '5-ingredients-or-less',\n",
        "  'breads',\n",
        "  'lunch'], 'hates': ['meat', 'lactose']}\n",
        "user2 = {'id':'8937', 'prefers': ['meat', 'beaf'], 'hates': ['vegetables']}\n",
        "user3 = {'id':'57222', 'prefers': [], 'hates': []}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS8T34Y4xNhX"
      },
      "source": [
        "We will additionally enter the factors Calories, Protein, Fat, Carbohydrates for our requirements. **(The numbers were taken at random and do not reflect proportions or recommendations - the numbers are just an example)**\n",
        "* User1 - 2000/100/60/120\n",
        "* User2, 2600/150/100/328.\n",
        "* User3 - 2200/80/50/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "qoPCpCLMxUob"
      },
      "outputs": [],
      "source": [
        "def set_requirements(user, calories, proteins, fats, carbs):\n",
        "  user['cal'] = calories\n",
        "  user['proteins'] = proteins\n",
        "  user['fat'] = fats\n",
        "  user['carbs'] = carbs\n",
        "set_requirements(user1, 2600, 120, 70, 120)\n",
        "set_requirements(user2, 2600, 150, 100, 328)\n",
        "set_requirements(user3, 2200, 80, 50, 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFMln3jutPpe"
      },
      "source": [
        "# Data processing üìä"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDHv_HGvzWkB"
      },
      "source": [
        "Loading recipes and user_interactions. Nutritions showed like:calories (#), total fat (PDV), sugar (PDV) , sodium (PDV) , protein (PDV) , saturated fat (PDV) , and carbohydrates (PDV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "1gVJ6QAiyXLz",
        "outputId": "0e6c0673-457a-4063-eaa5-b553ec30edc8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>id</th>\n",
              "      <th>minutes</th>\n",
              "      <th>contributor_id</th>\n",
              "      <th>submitted</th>\n",
              "      <th>tags</th>\n",
              "      <th>nutrition</th>\n",
              "      <th>n_steps</th>\n",
              "      <th>steps</th>\n",
              "      <th>description</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>n_ingredients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>arriba   baked winter squash mexican style</td>\n",
              "      <td>137739</td>\n",
              "      <td>55</td>\n",
              "      <td>47892</td>\n",
              "      <td>2005-09-16</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
              "      <td>11</td>\n",
              "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
              "      <td>autumn is my favorite time of year to cook! th...</td>\n",
              "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a bit different  breakfast pizza</td>\n",
              "      <td>31490</td>\n",
              "      <td>30</td>\n",
              "      <td>26278</td>\n",
              "      <td>2002-06-17</td>\n",
              "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
              "      <td>9</td>\n",
              "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
              "      <td>this recipe calls for the crust to be prebaked...</td>\n",
              "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>all in the kitchen  chili</td>\n",
              "      <td>112140</td>\n",
              "      <td>130</td>\n",
              "      <td>196586</td>\n",
              "      <td>2005-02-25</td>\n",
              "      <td>['time-to-make', 'course', 'preparation', 'mai...</td>\n",
              "      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n",
              "      <td>6</td>\n",
              "      <td>['brown ground beef in large pot', 'add choppe...</td>\n",
              "      <td>this modified version of 'mom's' chili was a h...</td>\n",
              "      <td>['ground beef', 'yellow onions', 'diced tomato...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>alouette  potatoes</td>\n",
              "      <td>59389</td>\n",
              "      <td>45</td>\n",
              "      <td>68585</td>\n",
              "      <td>2003-04-14</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]</td>\n",
              "      <td>11</td>\n",
              "      <td>['place potatoes in a large pot of lightly sal...</td>\n",
              "      <td>this is a super easy, great tasting, make ahea...</td>\n",
              "      <td>['spreadable cheese with garlic and herbs', 'n...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>amish  tomato ketchup  for canning</td>\n",
              "      <td>44061</td>\n",
              "      <td>190</td>\n",
              "      <td>41706</td>\n",
              "      <td>2002-10-25</td>\n",
              "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
              "      <td>[352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]</td>\n",
              "      <td>5</td>\n",
              "      <td>['mix all ingredients&amp; boil for 2 1 / 2 hours ...</td>\n",
              "      <td>my dh's amish mother raised him on this recipe...</td>\n",
              "      <td>['tomato juice', 'apple cider vinegar', 'sugar...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         name      id  minutes  \\\n",
              "0  arriba   baked winter squash mexican style  137739       55   \n",
              "1            a bit different  breakfast pizza   31490       30   \n",
              "2                   all in the kitchen  chili  112140      130   \n",
              "3                          alouette  potatoes   59389       45   \n",
              "4          amish  tomato ketchup  for canning   44061      190   \n",
              "\n",
              "   contributor_id   submitted  \\\n",
              "0           47892  2005-09-16   \n",
              "1           26278  2002-06-17   \n",
              "2          196586  2005-02-25   \n",
              "3           68585  2003-04-14   \n",
              "4           41706  2002-10-25   \n",
              "\n",
              "                                                tags  \\\n",
              "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
              "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
              "3  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "4  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
              "\n",
              "                                    nutrition  n_steps  \\\n",
              "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
              "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
              "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
              "3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
              "4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
              "\n",
              "                                               steps  \\\n",
              "0  ['make a choice and proceed with recipe', 'dep...   \n",
              "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
              "2  ['brown ground beef in large pot', 'add choppe...   \n",
              "3  ['place potatoes in a large pot of lightly sal...   \n",
              "4  ['mix all ingredients& boil for 2 1 / 2 hours ...   \n",
              "\n",
              "                                         description  \\\n",
              "0  autumn is my favorite time of year to cook! th...   \n",
              "1  this recipe calls for the crust to be prebaked...   \n",
              "2  this modified version of 'mom's' chili was a h...   \n",
              "3  this is a super easy, great tasting, make ahea...   \n",
              "4  my dh's amish mother raised him on this recipe...   \n",
              "\n",
              "                                         ingredients  n_ingredients  \n",
              "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n",
              "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  \n",
              "2  ['ground beef', 'yellow onions', 'diced tomato...             13  \n",
              "3  ['spreadable cheese with garlic and herbs', 'n...             11  \n",
              "4  ['tomato juice', 'apple cider vinegar', 'sugar...              8  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_recipes = pd.read_csv('./sample_data/RAW_recipes.csv')\n",
        "raw_interactions = pd.read_csv('./sample_data/RAW_interactions.csv')\n",
        "raw_recipes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_z_pQgv4fvC"
      },
      "source": [
        "Merge data interactions with recipe infos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ahU35J7P31xt",
        "outputId": "f26e3ef4-cfee-4ecd-b0bd-44e31a36503b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>recipe_name</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38094</td>\n",
              "      <td>4</td>\n",
              "      <td>white bean   green chile pepper soup</td>\n",
              "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1293707</td>\n",
              "      <td>5</td>\n",
              "      <td>white bean   green chile pepper soup</td>\n",
              "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8937</td>\n",
              "      <td>4</td>\n",
              "      <td>devilicious cookie cake delights</td>\n",
              "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>126440</td>\n",
              "      <td>5</td>\n",
              "      <td>baked potato toppings</td>\n",
              "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57222</td>\n",
              "      <td>5</td>\n",
              "      <td>baked potato toppings</td>\n",
              "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  rating                           recipe_name  \\\n",
              "0    38094       4  white bean   green chile pepper soup   \n",
              "1  1293707       5  white bean   green chile pepper soup   \n",
              "2     8937       4      devilicious cookie cake delights   \n",
              "3   126440       5                 baked potato toppings   \n",
              "4    57222       5                 baked potato toppings   \n",
              "\n",
              "                                                tags  \n",
              "0  ['weeknight', 'time-to-make', 'course', 'main-...  \n",
              "1  ['weeknight', 'time-to-make', 'course', 'main-...  \n",
              "2  ['30-minutes-or-less', 'time-to-make', 'course...  \n",
              "3  ['15-minutes-or-less', 'time-to-make', 'course...  \n",
              "4  ['15-minutes-or-less', 'time-to-make', 'course...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interactions_with_recipe_info = pd.merge(raw_interactions, raw_recipes[['name', 'tags', 'ingredients', 'id']], left_on='recipe_id', right_on='id', how='left')\n",
        "interactions_with_recipe_info = interactions_with_recipe_info[['user_id', 'rating', 'name', 'tags']]\n",
        "interactions_with_recipe_info.rename(columns={'name': 'recipe_name'}, inplace=True)\n",
        "interactions_with_recipe_info.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVgYKJQ57wyE"
      },
      "source": [
        "Formatting data for Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6wavCmee7zWl"
      },
      "outputs": [],
      "source": [
        "interactions_with_recipe_info['user_id'] = interactions_with_recipe_info.user_id.astype(\"str\")\n",
        "interactions_with_recipe_info['rating'] = interactions_with_recipe_info.rating.astype(np.float32)\n",
        "interactions_with_recipe_info['recipe_name'] = interactions_with_recipe_info.recipe_name.astype(\"str\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzycE1Re7X9i"
      },
      "source": [
        "Creating datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1QwBdlgU7Xms"
      },
      "outputs": [],
      "source": [
        "\n",
        "# –®–∞–≥ 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–ª–æ—è –≤ –∫–æ–Ω–≤–µ–π–µ—Ä–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
        "ratings = tf.data.Dataset.from_tensor_slices((\n",
        "    tf.cast(interactions_with_recipe_info['user_id'].values, tf.string),\n",
        "    tf.cast(interactions_with_recipe_info['recipe_name'].values, tf.string),\n",
        ")).map(lambda x, x1: {\n",
        "    \"user_id\": x,\n",
        "    \"recipe_name\": x1,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'user_id': b'38094', 'recipe_name': b'white bean   green chile pepper soup'}\n"
          ]
        }
      ],
      "source": [
        "for data in ratings.take(1).as_numpy_iterator():\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i8HzpEQW_YZw"
      },
      "outputs": [],
      "source": [
        "raw_recipes['id'] = raw_recipes.id.astype(\"str\")\n",
        "raw_recipes['name'] = raw_recipes.name.astype(\"str\")\n",
        "raw_recipes['tags'] = raw_recipes.tags.astype(\"str\")\n",
        "raw_recipes['ingredients'] = raw_recipes.ingredients.astype(\"str\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvNaaXXCPzK2",
        "outputId": "d096fdf6-825f-4105-b630-1f8c0d177652"
      },
      "outputs": [],
      "source": [
        "# prompt: –°–æ–∑–¥–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ raw_recipes –¥–∞—Ç–∞—Å–µ—Ç, –Ω–æ —É—á—Ç–∏ —á—Ç–æ ingredients_str —ç—Ç–æ –º–∞—Å—Å–∏–≤\n",
        "\n",
        "recipes = tf.data.Dataset.from_tensor_slices((tf.cast(raw_recipes['id'].values, tf.string),\n",
        "                                              tf.cast(raw_recipes['name'].values, tf.string),\n",
        "                                            #   tf.cast(raw_recipes['ingredients_str'].values.reshape(-1, 1), tf.string),\n",
        "                                              )\n",
        "                                             ).map(lambda x, x1: {\n",
        "                                                 'recipe_id': x,\n",
        "                                                  \"recipe_name\": x1,\n",
        "\n",
        "                                              })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'recipe_id': b'137739', 'recipe_name': b'arriba   baked winter squash mexican style'}\n"
          ]
        }
      ],
      "source": [
        "for data in recipes.take(1).as_numpy_iterator():\n",
        "  print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jxTLSUjNgCLs"
      },
      "outputs": [],
      "source": [
        "recipe_names = tf.data.Dataset.from_tensor_slices((tf.cast(raw_recipes['name'].values.reshape(-1, 1), tf.string))).map(lambda x: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L-UtJ6K5N2B"
      },
      "source": [
        "# Towers üóº"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWGCI8IYBx3Z"
      },
      "source": [
        "For our towers set dimensionality of the query and candidate representations: **32**. Higher values will correspond to models that may be more accurate, but will also be slower to fit and more prone to overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8H35ROAtB2L2"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLl4NdNBHoH"
      },
      "source": [
        "## User tower üë∑"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_w7g9Se6Lk_"
      },
      "source": [
        "Lets start creating our towers with User towers. We will compute by User id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0pr_riLBCKa"
      },
      "source": [
        "### User ID model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVERCEAMPPbE",
        "outputId": "e2631cda-7833-44b7-b005-542bb5f24933"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['38094', '1293707', '8937', '126440', '57222', '52282', '124416',\n",
              "       '2000192946', '76535', '273745'], dtype=object)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique_user_ids = interactions_with_recipe_info[\"user_id\"].unique()\n",
        "unique_user_ids[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\azdanevy\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_id_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_user_ids, mask_token='new_user'),\n",
        "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "        ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6e5kR2_MsOh"
      },
      "source": [
        "### User Prefers models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zt9V_nAHMqp"
      },
      "source": [
        "## Recipe tower üå≠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2VwZxnOCg9F"
      },
      "source": [
        "### Recipe name model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3zzDVmWJmSA",
        "outputId": "2b48e837-bb5f-4670-b353-bb91770413dd"
      },
      "outputs": [],
      "source": [
        "unique_recipe_names = raw_recipes[\"name\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqUQ43gVQIUp",
        "outputId": "49f54edf-1d29-4efc-e338-84c05a6f7e16"
      },
      "outputs": [],
      "source": [
        "recipe_name_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_recipe_names, mask_token=None),\n",
        "            tf.keras.layers.Embedding(len(unique_recipe_names) + 1, embedding_dimension)\n",
        "        ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1dQh7uGI2ow"
      },
      "source": [
        "## Combine models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RecipeAndUserModel(tfrs.Model):\n",
        "\n",
        "    def _reduce_mean_if_needed(self, embedding):\n",
        "\n",
        "        if len(embedding.shape) >= 3:\n",
        "            return tf.reduce_mean(embedding, axis=1)\n",
        "        return embedding\n",
        "\n",
        "    def __init__(self, recipe_name_model, user_id_model):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_model = user_id_model\n",
        "        self.recipe_name_model = recipe_name_model\n",
        "        self.candidates = recipes.batch(128).map( lambda x: recipe_name_model(x['recipe_name']))\n",
        "        self.task = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=self.candidates\n",
        "            )\n",
        "        )\n",
        "        \n",
        "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "        \n",
        "        user_embedding = self.user_model(features['user_id'])\n",
        "        recipe_embeddings = self.recipe_name_model(features['recipe_name'])\n",
        "        \n",
        "        return user_embedding, recipe_embeddings\n",
        "\n",
        "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "        user_embeddings, recipe_embeddings = self(features)\n",
        "        return self.task(user_embeddings, recipe_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4ln6bTE6XuUT"
      },
      "outputs": [],
      "source": [
        "# Randomly shuffle data and split between train and test.\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(200_000)\n",
        "test = shuffled.skip(len(train)).take(100_000)\n",
        "\n",
        "cached_train =  train.batch(4_000).cache()\n",
        "cached_test = test.batch(15_000).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-7Gi0OYpUbOM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\azdanevy\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "Epoch 1/10\n",
            "50/50 [==============================] - 643s 13s/step - factorized_top_k/top_1_categorical_accuracy: 8.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0027 - factorized_top_k/top_10_categorical_accuracy: 0.0052 - factorized_top_k/top_50_categorical_accuracy: 0.0174 - factorized_top_k/top_100_categorical_accuracy: 0.0270 - loss: 33026.5420 - regularization_loss: 0.0000e+00 - total_loss: 33026.5420\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 635s 13s/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0359 - factorized_top_k/top_10_categorical_accuracy: 0.0517 - factorized_top_k/top_50_categorical_accuracy: 0.1048 - factorized_top_k/top_100_categorical_accuracy: 0.1395 - loss: 32228.7117 - regularization_loss: 0.0000e+00 - total_loss: 32228.7117\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 614s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0053 - factorized_top_k/top_5_categorical_accuracy: 0.0949 - factorized_top_k/top_10_categorical_accuracy: 0.1234 - factorized_top_k/top_50_categorical_accuracy: 0.2067 - factorized_top_k/top_100_categorical_accuracy: 0.2562 - loss: 30472.0358 - regularization_loss: 0.0000e+00 - total_loss: 30472.0358\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 621s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0147 - factorized_top_k/top_5_categorical_accuracy: 0.1578 - factorized_top_k/top_10_categorical_accuracy: 0.1944 - factorized_top_k/top_50_categorical_accuracy: 0.2950 - factorized_top_k/top_100_categorical_accuracy: 0.3722 - loss: 27851.7635 - regularization_loss: 0.0000e+00 - total_loss: 27851.7635\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 616s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0292 - factorized_top_k/top_5_categorical_accuracy: 0.2127 - factorized_top_k/top_10_categorical_accuracy: 0.2516 - factorized_top_k/top_50_categorical_accuracy: 0.3925 - factorized_top_k/top_100_categorical_accuracy: 0.4917 - loss: 25264.2628 - regularization_loss: 0.0000e+00 - total_loss: 25264.2628\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 618s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0406 - factorized_top_k/top_5_categorical_accuracy: 0.2539 - factorized_top_k/top_10_categorical_accuracy: 0.2965 - factorized_top_k/top_50_categorical_accuracy: 0.4691 - factorized_top_k/top_100_categorical_accuracy: 0.5636 - loss: 23041.3277 - regularization_loss: 0.0000e+00 - total_loss: 23041.3277\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 622s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0489 - factorized_top_k/top_5_categorical_accuracy: 0.2838 - factorized_top_k/top_10_categorical_accuracy: 0.3327 - factorized_top_k/top_50_categorical_accuracy: 0.5196 - factorized_top_k/top_100_categorical_accuracy: 0.6172 - loss: 21158.9796 - regularization_loss: 0.0000e+00 - total_loss: 21158.9796\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 617s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0572 - factorized_top_k/top_5_categorical_accuracy: 0.3081 - factorized_top_k/top_10_categorical_accuracy: 0.3668 - factorized_top_k/top_50_categorical_accuracy: 0.5559 - factorized_top_k/top_100_categorical_accuracy: 0.6479 - loss: 19563.8441 - regularization_loss: 0.0000e+00 - total_loss: 19563.8441\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 617s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0652 - factorized_top_k/top_5_categorical_accuracy: 0.3295 - factorized_top_k/top_10_categorical_accuracy: 0.3957 - factorized_top_k/top_50_categorical_accuracy: 0.5823 - factorized_top_k/top_100_categorical_accuracy: 0.6729 - loss: 18195.5875 - regularization_loss: 0.0000e+00 - total_loss: 18195.5875\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 621s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0738 - factorized_top_k/top_5_categorical_accuracy: 0.3496 - factorized_top_k/top_10_categorical_accuracy: 0.4202 - factorized_top_k/top_50_categorical_accuracy: 0.5999 - factorized_top_k/top_100_categorical_accuracy: 0.6827 - loss: 17024.9214 - regularization_loss: 0.0000e+00 - total_loss: 17024.9214\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x12e1921f850>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RecipeAndUserModel(recipe_name_model, user_id_model)\n",
        "early_callback = tf.keras.callbacks.EarlyStopping(monitor='loss',  patience=5, min_delta=0.001)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
        "model.fit(cached_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 304s 43s/step - factorized_top_k/top_1_categorical_accuracy: 3.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 4.7000e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0041 - factorized_top_k/top_100_categorical_accuracy: 0.0070 - loss: 147914.5801 - regularization_loss: 0.0000e+00 - total_loss: 147914.5801\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'factorized_top_k/top_1_categorical_accuracy': 2.9999999242136255e-05,\n",
              " 'factorized_top_k/top_5_categorical_accuracy': 0.00046999999904073775,\n",
              " 'factorized_top_k/top_10_categorical_accuracy': 0.001019999966956675,\n",
              " 'factorized_top_k/top_50_categorical_accuracy': 0.004110000096261501,\n",
              " 'factorized_top_k/top_100_categorical_accuracy': 0.007029999978840351,\n",
              " 'loss': 102549.1171875,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 102549.1171875}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000012E70F1B130> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x0000012E70F1B130>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "lambda x: x['recipe_id']\n",
            "\n",
            "Match 1:\n",
            "lambda x: x['recipe_name']\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000012E70F1B130> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x0000012E70F1B130>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "lambda x: x['recipe_id']\n",
            "\n",
            "Match 1:\n",
            "lambda x: x['recipe_name']\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function <lambda> at 0x0000012E70F1B130> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x0000012E70F1B130>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "lambda x: x['recipe_id']\n",
            "\n",
            "Match 1:\n",
            "lambda x: x['recipe_name']\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000012E735E11B0> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x0000012E735E11B0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "lambda x: x['recipe_id']\n",
            "\n",
            "Match 1:\n",
            "lambda x: x['recipe_name']\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000012E735E11B0> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x0000012E735E11B0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "lambda x: x['recipe_id']\n",
            "\n",
            "Match 1:\n",
            "lambda x: x['recipe_name']\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function <lambda> at 0x0000012E735E11B0> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x0000012E735E11B0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
            "Match 0:\n",
            "lambda x: x['recipe_id']\n",
            "\n",
            "Match 1:\n",
            "lambda x: x['recipe_name']\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Recommendations for user 42: [b'146320' b'95220' b'120444']\n"
          ]
        }
      ],
      "source": [
        "# Create a model that takes in raw query features, and\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "# recommends movies out of the entire movies dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((recipes.batch(100).map(lambda x: x['recipe_id']), recipes.batch(100).map(lambda x: x['recipe_name']).map(model.recipe_name_model)))\n",
        ")\n",
        "# Get recommendations.\n",
        "_, titles2 = index(tf.constant([\"42\"]))\n",
        "print(f\"Recommendations for user 42: {titles2[0, :3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./model2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./model2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendations: [b'39446' b'204257' b'134316']\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(index, \"./model2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendations: \n"
          ]
        }
      ],
      "source": [
        " # Load it back; can also be done in TensorFlow Serving.\n",
        "loaded = tf.saved_model.load(\"./model2\")\n",
        "# Pass a user id in, get top predicted movie titles back.\n",
        "scores, titles = loaded([\"1293707\"])\n",
        "print(f\"Recommendations: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendations for user 42: [b'39446' b'204257' b'134316']\n"
          ]
        }
      ],
      "source": [
        "# Get recommendations.\n",
        "_, titles = loaded([user1['id']])\n",
        "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Processing results üèÅ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x2211b236cb0>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "def convert_to_list(data_str):\n",
        "  try:\n",
        "    return ast.literal_eval(data_str)\n",
        "  except (SyntaxError, ValueError):\n",
        "    return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>tags</th>\n",
              "      <th>nutrition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23754</th>\n",
              "      <td>510874</td>\n",
              "      <td>biscuits   gravy breakfast casserole</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[613.7, 61.0, 17.0, 85.0, 49.0, 72.0, 12.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111026</th>\n",
              "      <td>132397</td>\n",
              "      <td>indian lentil soup  dal shorva</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[498.9, 25.0, 24.0, 22.0, 58.0, 13.0, 20.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117239</th>\n",
              "      <td>156331</td>\n",
              "      <td>kfc coleslaw copycat recipe by todd wilbur</td>\n",
              "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[81.4, 0.0, 59.0, 9.0, 3.0, 1.0, 6.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118767</th>\n",
              "      <td>39446</td>\n",
              "      <td>koshari</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[359.9, 9.0, 20.0, 0.0, 28.0, 4.0, 20.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161923</th>\n",
              "      <td>204257</td>\n",
              "      <td>polenta lasagna with feta and kale</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[193.7, 20.0, 23.0, 24.0, 13.0, 28.0, 4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171095</th>\n",
              "      <td>2941</td>\n",
              "      <td>raspberry sherbet punch</td>\n",
              "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[103.2, 1.0, 79.0, 1.0, 1.0, 2.0, 7.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171258</th>\n",
              "      <td>52491</td>\n",
              "      <td>ratatouille</td>\n",
              "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
              "      <td>[113.8, 1.0, 53.0, 7.0, 10.0, 1.0, 8.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218616</th>\n",
              "      <td>134316</td>\n",
              "      <td>turnip and carrot mash</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[78.3, 0.0, 38.0, 6.0, 4.0, 0.0, 6.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228148</th>\n",
              "      <td>204013</td>\n",
              "      <td>workday borscht  vegetarian  crock pot</td>\n",
              "      <td>['course', 'main-ingredient', 'cuisine', 'prep...</td>\n",
              "      <td>[98.9, 0.0, 18.0, 2.0, 6.0, 0.0, 7.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230850</th>\n",
              "      <td>25509</td>\n",
              "      <td>zucchini  pasta  with fresh tomato sauce</td>\n",
              "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[160.6, 17.0, 33.0, 14.0, 8.0, 8.0, 4.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                        name  \\\n",
              "23754   510874        biscuits   gravy breakfast casserole   \n",
              "111026  132397              indian lentil soup  dal shorva   \n",
              "117239  156331  kfc coleslaw copycat recipe by todd wilbur   \n",
              "118767   39446                                     koshari   \n",
              "161923  204257          polenta lasagna with feta and kale   \n",
              "171095    2941                     raspberry sherbet punch   \n",
              "171258   52491                                 ratatouille   \n",
              "218616  134316                      turnip and carrot mash   \n",
              "228148  204013      workday borscht  vegetarian  crock pot   \n",
              "230850   25509    zucchini  pasta  with fresh tomato sauce   \n",
              "\n",
              "                                                     tags  \\\n",
              "23754   ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "111026  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "117239  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
              "118767  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "161923  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "171095  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
              "171258  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
              "218616  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "228148  ['course', 'main-ingredient', 'cuisine', 'prep...   \n",
              "230850  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
              "\n",
              "                                          nutrition  \n",
              "23754   [613.7, 61.0, 17.0, 85.0, 49.0, 72.0, 12.0]  \n",
              "111026  [498.9, 25.0, 24.0, 22.0, 58.0, 13.0, 20.0]  \n",
              "117239        [81.4, 0.0, 59.0, 9.0, 3.0, 1.0, 6.0]  \n",
              "118767     [359.9, 9.0, 20.0, 0.0, 28.0, 4.0, 20.0]  \n",
              "161923   [193.7, 20.0, 23.0, 24.0, 13.0, 28.0, 4.0]  \n",
              "171095       [103.2, 1.0, 79.0, 1.0, 1.0, 2.0, 7.0]  \n",
              "171258      [113.8, 1.0, 53.0, 7.0, 10.0, 1.0, 8.0]  \n",
              "218616        [78.3, 0.0, 38.0, 6.0, 4.0, 0.0, 6.0]  \n",
              "228148        [98.9, 0.0, 18.0, 2.0, 6.0, 0.0, 7.0]  \n",
              "230850     [160.6, 17.0, 33.0, 14.0, 8.0, 8.0, 4.0]  "
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_recipes = raw_recipes[raw_recipes['id'].isin(titles.numpy().flatten().astype('str'))][['id','name','tags', 'nutrition']]\n",
        "selected_recipes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_recipes['tags'] = selected_recipes['tags'].apply(convert_to_list)\n",
        "selected_recipes['nutrition'] = selected_recipes['nutrition'].apply(convert_to_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_tags = set()\n",
        "for tags in raw_recipes['tags'].apply(convert_to_list):\n",
        "  if isinstance(tags, list):\n",
        "    for tag in tags:\n",
        "      unique_tags.add(tag)\n",
        "unique_tags = np.unique(list(unique_tags))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_TAG_LENGTH = len(selected_recipes['tags'].max())\n",
        "PADDING_VALUE = \"\"\n",
        "\n",
        "selected_recipes['tags'] = [\n",
        "    (tags + [PADDING_VALUE] * (MAX_TAG_LENGTH - len(tags)))[:MAX_TAG_LENGTH] \n",
        "    for tags in selected_recipes['tags']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\azdanevy\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\azdanevy\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "vectorizer = TextVectorization(output_mode='int')\n",
        "vectorizer.adapt(unique_tags)\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "def compute_percent_personality(user_tags, recipe_tags):\n",
        "    user_tags_vectorized = vectorizer(user_tags)\n",
        "    recipe_tags_vectorized = vectorizer(recipe_tags)\n",
        "    user_tags_embedded = embedding_layer(user_tags_vectorized)\n",
        "    recipe_tags_embedded = embedding_layer(recipe_tags_vectorized)\n",
        "    user_vector = tf.reduce_mean(user_tags_embedded, axis=0)  # [embedding_dim]\n",
        "    recipe_vector = tf.reduce_mean(recipe_tags_embedded, axis=0)  # [embedding_dim]\n",
        "    \n",
        "    cosine_similarity = tf.keras.losses.cosine_similarity(user_vector, recipe_vector, axis=-1)\n",
        "    similarity_percentage = (1 - cosine_similarity) /2 * 100\n",
        "    return  similarity_percentage.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_recipes['similarity_tags'] = selected_recipes['tags'].apply(lambda x: compute_percent_personality(user1['prefers'], x))\n",
        "selected_recipes = selected_recipes.sort_values(by=['similarity_tags'], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>tags</th>\n",
              "      <th>nutrition</th>\n",
              "      <th>similarity_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23754</th>\n",
              "      <td>510874</td>\n",
              "      <td>biscuits   gravy breakfast casserole</td>\n",
              "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
              "      <td>[613.7, 61.0, 17.0, 85.0, 49.0, 72.0, 12.0]</td>\n",
              "      <td>[81.44639]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171095</th>\n",
              "      <td>2941</td>\n",
              "      <td>raspberry sherbet punch</td>\n",
              "      <td>[15-minutes-or-less, time-to-make, course, mai...</td>\n",
              "      <td>[103.2, 1.0, 79.0, 1.0, 1.0, 2.0, 7.0]</td>\n",
              "      <td>[79.40008]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117239</th>\n",
              "      <td>156331</td>\n",
              "      <td>kfc coleslaw copycat recipe by todd wilbur</td>\n",
              "      <td>[15-minutes-or-less, time-to-make, course, mai...</td>\n",
              "      <td>[81.4, 0.0, 59.0, 9.0, 3.0, 1.0, 6.0]</td>\n",
              "      <td>[76.19014]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                        name  \\\n",
              "23754   510874        biscuits   gravy breakfast casserole   \n",
              "171095    2941                     raspberry sherbet punch   \n",
              "117239  156331  kfc coleslaw copycat recipe by todd wilbur   \n",
              "\n",
              "                                                     tags  \\\n",
              "23754   [60-minutes-or-less, time-to-make, course, mai...   \n",
              "171095  [15-minutes-or-less, time-to-make, course, mai...   \n",
              "117239  [15-minutes-or-less, time-to-make, course, mai...   \n",
              "\n",
              "                                          nutrition similarity_tags  \n",
              "23754   [613.7, 61.0, 17.0, 85.0, 49.0, 72.0, 12.0]      [81.44639]  \n",
              "171095       [103.2, 1.0, 79.0, 1.0, 1.0, 2.0, 7.0]      [79.40008]  \n",
              "117239        [81.4, 0.0, 59.0, 9.0, 3.0, 1.0, 6.0]      [76.19014]  "
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_recipes[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Processing portions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±–æ–ª–æ—á–∫—É OR-Tools –¥–ª—è –ª–∏–Ω–µ–π–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "from ortools.linear_solver import pywraplp\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º —Ä–µ—à–∞—Ç–µ–ª—å —Å –ø–æ–º–æ—â—å—é –±—ç–∫–µ–Ω–¥–∞ GLOP\n",
        "solver = pywraplp.Solver('Find optimal weights', pywraplp.Solver.GLOP_LINEAR_PROGRAMMING)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So we deciding, that every our dish can be from 100 gr to 500 gr."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
        "w1 = solver.IntVar(50, 500, 'weight1')\n",
        "w2 = solver.IntVar(50, 500, 'weight2')\n",
        "w3 = solver.IntVar(50, 500, 'weight3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([list([613.7, 61.0, 17.0, 85.0, 49.0, 72.0, 12.0]),\n",
              "       list([103.2, 1.0, 79.0, 1.0, 1.0, 2.0, 7.0]),\n",
              "       list([81.4, 0.0, 59.0, 9.0, 3.0, 1.0, 6.0])], dtype=object)"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nutrition_info = selected_recipes[:3]['nutrition'].to_numpy()\n",
        "nutrition_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "first_dish = {'cal':nutrition_info[0][0]/100, 'fat':nutrition_info[0][1]/100, 'carbs': nutrition_info[0][2]/100, 'proteins':nutrition_info[0][4]/100}\n",
        "second_dish = {'cal':nutrition_info[1][0]/100, 'fat':nutrition_info[1][1]/100, 'carbs': nutrition_info[1][2]/100, 'proteins':nutrition_info[1][4]/100}\n",
        "third_dish = {'cal':nutrition_info[2][0]/100, 'fat':nutrition_info[2][1]/100, 'carbs': nutrition_info[2][2]/100, 'proteins':nutrition_info[2][4]/100}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '1293707',\n",
              " 'prefers': ['30-minutes-or-less',\n",
              "  'time-to-make',\n",
              "  'course',\n",
              "  'preparation',\n",
              "  'occasion',\n",
              "  'for-large-groups',\n",
              "  'low-protein',\n",
              "  'healthy',\n",
              "  '5-ingredients-or-less',\n",
              "  'breads',\n",
              "  'lunch'],\n",
              " 'hates': ['meat', 'lactose'],\n",
              " 'cal': 2600,\n",
              " 'proteins': 120,\n",
              " 'fat': 70,\n",
              " 'carbs': 120}"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ortools.linear_solver.pywraplp.Constraint; proxy of <Swig Object of type 'operations_research::MPConstraint *' at 0x000002213CAE9140> >"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "solver.Add(first_dish[\"proteins\"] * w1 + second_dish[\"proteins\"] * w2 + third_dish[\"proteins\"] * w3 <= user1['proteins'])\n",
        "solver.Add(first_dish[\"carbs\"] * w1 + second_dish[\"carbs\"] * w2 + third_dish[\"carbs\"] * w3 <= user1['carbs'])\n",
        "solver.Add(first_dish[\"fat\"] * w1 + second_dish[\"fat\"] * w2 + third_dish[\"fat\"] * w3 <= user1['fat'])\n",
        "solver.Add(first_dish[\"cal\"] * w1 + second_dish[\"cal\"] * w2 + third_dish[\"cal\"] * w3 <= user1['cal'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "solver.Maximize(first_dish[\"cal\"] * w1 + second_dish[\"cal\"] * w2 + third_dish[\"cal\"] * w3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================= Solution =================\n",
            "Solved in 114476.00 milliseconds in 0 iterations\n",
            "\n",
            "Optimal power = 835.155834954154 üí™power\n",
            "Army:\n",
            " - Weight 1 = 113.9344262295082\n",
            " - Weight 2 = 50.0\n",
            " - Weight 3 = 103.61211447624339\n"
          ]
        }
      ],
      "source": [
        "status = solver.Solve()\n",
        "\n",
        "# –ï—Å–ª–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ, –≤—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "if status == pywraplp.Solver.OPTIMAL:\n",
        "  print('================= Solution =================')\n",
        "  print(f'Solved in {solver.wall_time():.2f} milliseconds in {solver.iterations()} iterations')\n",
        "  print()\n",
        "  print(f'Optimal power = {solver.Objective().Value()} üí™power')\n",
        "  print('Army:')\n",
        "  print(f' - Weight 1 = {w1.solution_value()}')\n",
        "  print(f' - Weight 2 = {w2.solution_value()}')\n",
        "  print(f' - Weight 3 = {w3.solution_value()}')\n",
        "else:\n",
        "  print('The solver could not find an optimal solution.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

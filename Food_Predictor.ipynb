{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rptU6mxyaoP"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16W1-BvjtVmz"
      },
      "source": [
        "Let's pretend we have 3 users:\n",
        "1. User 1 is a vegetarian who is lactose intolerant. ü•ùüçÖ\n",
        "2. Unser 2 is an athlete who prefers meat dishes to vegetable dishes. üçñü•©\n",
        "3. Unser 3 - has no special preferences, eats mostly everything. üç≤üç†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FDNshkxJvR-U"
      },
      "outputs": [],
      "source": [
        "user1 = {'id':'clr', 'prefers': ['vegetables', 'vegan', 'nomeat', 'vegetarian'], 'hates': ['meat', 'lactose']}\n",
        "user2 = {'id':'mrt', 'prefers': 'meat', 'hates': 'vegetables'}\n",
        "user3 = {'id':'stl', 'prefers': '', 'hates': ''}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS8T34Y4xNhX"
      },
      "source": [
        "We will additionally enter the factors Calories, Protein, Fat, Carbohydrates for our requirements. **(The numbers were taken at random and do not reflect proportions or recommendations - the numbers are just an example)**\n",
        "* User1 - 2000/100/60/120\n",
        "* User2, 2600/150/100/328.\n",
        "* User3 - 2200/80/50/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qoPCpCLMxUob"
      },
      "outputs": [],
      "source": [
        "def set_requirements(user, calories, proteins, fats, carbs):\n",
        "  user['calories'] = calories\n",
        "  user['proteins'] = proteins\n",
        "  user['fats'] = fats\n",
        "  user['carbs'] = carbs\n",
        "set_requirements(user1, 2000, 100, 60, 120)\n",
        "set_requirements(user2, 2600, 150, 100, 328)\n",
        "set_requirements(user3, 2200, 80, 50, 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFMln3jutPpe"
      },
      "source": [
        "# Data processing üìä"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDHv_HGvzWkB"
      },
      "source": [
        "Loading recipes and user_interactions. Nutritions showed like:calories (#), total fat (PDV), sugar (PDV) , sodium (PDV) , protein (PDV) , saturated fat (PDV) , and carbohydrates (PDV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "1gVJ6QAiyXLz",
        "outputId": "0e6c0673-457a-4063-eaa5-b553ec30edc8"
      },
      "outputs": [],
      "source": [
        "raw_recipes = pd.read_csv('./sample_data/RAW_recipes.csv')\n",
        "raw_interactions = pd.read_csv('./sample_data/RAW_interactions.csv')\n",
        "raw_recipes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_z_pQgv4fvC"
      },
      "source": [
        "Merge data interactions with recipe infos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ahU35J7P31xt",
        "outputId": "f26e3ef4-cfee-4ecd-b0bd-44e31a36503b"
      },
      "outputs": [],
      "source": [
        "interactions_with_recipe_info = pd.merge(raw_interactions, raw_recipes[['name', 'tags', 'ingredients', 'id']], left_on='recipe_id', right_on='id', how='left')\n",
        "interactions_with_recipe_info = interactions_with_recipe_info[['user_id', 'rating', 'name', 'tags']]\n",
        "interactions_with_recipe_info.rename(columns={'name': 'recipe_name'}, inplace=True)\n",
        "interactions_with_recipe_info.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVgYKJQ57wyE"
      },
      "source": [
        "Formatting data for Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6wavCmee7zWl"
      },
      "outputs": [],
      "source": [
        "interactions_with_recipe_info['user_id'] = interactions_with_recipe_info.user_id.astype(\"str\")\n",
        "interactions_with_recipe_info['rating'] = interactions_with_recipe_info.rating.astype(np.float32)\n",
        "interactions_with_recipe_info['recipe_name'] = interactions_with_recipe_info.recipe_name.astype(\"str\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzycE1Re7X9i"
      },
      "source": [
        "Creating datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1QwBdlgU7Xms"
      },
      "outputs": [],
      "source": [
        "\n",
        "# –®–∞–≥ 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–ª–æ—è –≤ –∫–æ–Ω–≤–µ–π–µ—Ä–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
        "ratings = tf.data.Dataset.from_tensor_slices((\n",
        "    tf.cast(interactions_with_recipe_info['user_id'].values, tf.string),\n",
        "    tf.cast(interactions_with_recipe_info['recipe_name'].values, tf.string),\n",
        ")).map(lambda x, x1: {\n",
        "    \"user_id\": x,\n",
        "    \"recipe_name\": x1,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in ratings.take(1).as_numpy_iterator():\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i8HzpEQW_YZw"
      },
      "outputs": [],
      "source": [
        "raw_recipes['id'] = raw_recipes.id.astype(\"str\")\n",
        "raw_recipes['name'] = raw_recipes.name.astype(\"str\")\n",
        "raw_recipes['tags'] = raw_recipes.tags.astype(\"str\")\n",
        "raw_recipes['ingredients'] = raw_recipes.ingredients.astype(\"str\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvNaaXXCPzK2",
        "outputId": "d096fdf6-825f-4105-b630-1f8c0d177652"
      },
      "outputs": [],
      "source": [
        "# prompt: –°–æ–∑–¥–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ raw_recipes –¥–∞—Ç–∞—Å–µ—Ç, –Ω–æ —É—á—Ç–∏ —á—Ç–æ ingredients_str —ç—Ç–æ –º–∞—Å—Å–∏–≤\n",
        "\n",
        "recipes = tf.data.Dataset.from_tensor_slices((tf.cast(raw_recipes['id'].values, tf.string),\n",
        "                                              tf.cast(raw_recipes['name'].values, tf.string),\n",
        "                                            #   tf.cast(raw_recipes['ingredients_str'].values.reshape(-1, 1), tf.string),\n",
        "                                              )\n",
        "                                             ).map(lambda x, x1: {\n",
        "                                                 'recipe_id': x,\n",
        "                                                  \"recipe_name\": x1,\n",
        "\n",
        "                                              })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in recipes.take(1).as_numpy_iterator():\n",
        "  print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jxTLSUjNgCLs"
      },
      "outputs": [],
      "source": [
        "recipe_names = tf.data.Dataset.from_tensor_slices((tf.cast(raw_recipes['name'].values.reshape(-1, 1), tf.string))).map(lambda x: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L-UtJ6K5N2B"
      },
      "source": [
        "# Towers üóº"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWGCI8IYBx3Z"
      },
      "source": [
        "For our towers set dimensionality of the query and candidate representations: **32**. Higher values will correspond to models that may be more accurate, but will also be slower to fit and more prone to overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8H35ROAtB2L2"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLl4NdNBHoH"
      },
      "source": [
        "## User tower üë∑"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_w7g9Se6Lk_"
      },
      "source": [
        "Lets start creating our towers with User towers. We will compute by User id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0pr_riLBCKa"
      },
      "source": [
        "### User ID model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVERCEAMPPbE",
        "outputId": "e2631cda-7833-44b7-b005-542bb5f24933"
      },
      "outputs": [],
      "source": [
        "unique_user_ids = interactions_with_recipe_info[\"user_id\"].unique()\n",
        "unique_user_ids[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_id_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_user_ids, mask_token=None),\n",
        "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "        ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6e5kR2_MsOh"
      },
      "source": [
        "### User Prefers models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zt9V_nAHMqp"
      },
      "source": [
        "## Recipe tower üå≠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2VwZxnOCg9F"
      },
      "source": [
        "### Recipe name model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3zzDVmWJmSA",
        "outputId": "2b48e837-bb5f-4670-b353-bb91770413dd"
      },
      "outputs": [],
      "source": [
        "unique_recipe_names = raw_recipes[\"name\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqUQ43gVQIUp",
        "outputId": "49f54edf-1d29-4efc-e338-84c05a6f7e16"
      },
      "outputs": [],
      "source": [
        "recipe_name_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_recipe_names, mask_token=None),\n",
        "            tf.keras.layers.Embedding(len(unique_recipe_names) + 1, embedding_dimension)\n",
        "        ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1dQh7uGI2ow"
      },
      "source": [
        "## Combine models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RecipeAndUserModel(tfrs.Model):\n",
        "\n",
        "    def _reduce_mean_if_needed(self, embedding):\n",
        "\n",
        "        if len(embedding.shape) >= 3:\n",
        "            return tf.reduce_mean(embedding, axis=1)\n",
        "        return embedding\n",
        "\n",
        "    def __init__(self, recipe_name_model, user_id_model):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_model = user_id_model\n",
        "        self.recipe_name_model = recipe_name_model\n",
        "        self.candidates = recipes.batch(128).map( lambda x: recipe_name_model(x['recipe_name']))\n",
        "        self.task = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=self.candidates\n",
        "            )\n",
        "        )\n",
        "        \n",
        "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "        \n",
        "        user_embedding = self.user_model(features['user_id'])\n",
        "        recipe_embeddings = self.recipe_name_model(features['recipe_name'])\n",
        "        \n",
        "        return user_embedding, recipe_embeddings\n",
        "\n",
        "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "        user_embeddings, recipe_embeddings = self(features)\n",
        "        return self.task(user_embeddings, recipe_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4ln6bTE6XuUT"
      },
      "outputs": [],
      "source": [
        "# Randomly shuffle data and split between train and test.\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(200_000)\n",
        "test = shuffled.skip(len(train)).take(100_000)\n",
        "\n",
        "cached_train =  train.batch(4_000).cache()\n",
        "cached_test = test.batch(15_000).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7Gi0OYpUbOM"
      },
      "outputs": [],
      "source": [
        "model = RecipeAndUserModel(recipe_name_model, user_id_model)\n",
        "early_callback = tf.keras.callbacks.EarlyStopping(monitor='loss',  patience=5, min_delta=0.001)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
        "model.fit(cached_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a model that takes in raw query features, and\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "# recommends movies out of the entire movies dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((recipes.batch(100).map(lambda x: x['recipe_id']), recipes.batch(100).map(lambda x: x['recipe_name']).map(model.recipe_name_model)))\n",
        ")\n",
        "# Get recommendations.\n",
        "_, titles2 = index(tf.constant([\"42\"]))\n",
        "print(f\"Recommendations for user 42: {titles2[0, :3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the query model.\n",
        "import tempfile\n",
        "\n",
        "\n",
        "with tempfile.TemporaryDirectory() as tmp:\n",
        "  path = os.path.join(tmp, \"model\")\n",
        "\n",
        "  # Save the index.\n",
        "  tf.saved_model.save(index, \"./model\")\n",
        "\n",
        "  # Load it back; can also be done in TensorFlow Serving.\n",
        "  loaded = tf.saved_model.load(\"./model\")\n",
        "\n",
        "  # Pass a user id in, get top predicted movie titles back.\n",
        "  scores, titles = loaded([\"1293707\"])\n",
        "  print(f\"Recommendations: {titles[0][:3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get recommendations.\n",
        "_, titles = index(tf.constant([\"1293707\"]))\n",
        "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
